{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Billboard banner](https://www.clipartkey.com/mpngs/m/62-628657_billboard-logo-png-billboard-top-100.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All neccessary libraries imported\n"
     ]
    }
   ],
   "source": [
    "# Import the neccessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import numpy as np\n",
    "print(\"All neccessary libraries imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed value for the notebook so the results are reproducible\n",
    "from numpy.random import seed\n",
    "seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data from Resources directory (change the link as needed)\n",
    "attribute_data = \"Resources/BillboardFromLast20/songAttributes_1999-2019.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mThe shape of the attribute dataframe is (154931, 14):\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Explicit</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>TimeSignature</th>\n",
       "      <th>Valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.520</td>\n",
       "      <td>234947</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.0634</td>\n",
       "      <td>-5.030</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0309</td>\n",
       "      <td>106.022</td>\n",
       "      <td>4</td>\n",
       "      <td>0.365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.018200</td>\n",
       "      <td>0.581</td>\n",
       "      <td>239573</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.1740</td>\n",
       "      <td>-4.909</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>120.027</td>\n",
       "      <td>4</td>\n",
       "      <td>0.408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.572</td>\n",
       "      <td>198400</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.0977</td>\n",
       "      <td>-3.324</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0559</td>\n",
       "      <td>144.061</td>\n",
       "      <td>4</td>\n",
       "      <td>0.370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000970</td>\n",
       "      <td>0.596</td>\n",
       "      <td>231453</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>-5.051</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0254</td>\n",
       "      <td>111.975</td>\n",
       "      <td>4</td>\n",
       "      <td>0.183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.520</td>\n",
       "      <td>222520</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>-4.553</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0318</td>\n",
       "      <td>92.721</td>\n",
       "      <td>4</td>\n",
       "      <td>0.666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Acousticness  Danceability  Duration  Energy  Explicit  Instrumentalness  \\\n",
       "0      0.000728         0.520    234947   0.904         0          0.010300   \n",
       "1      0.018200         0.581    239573   0.709         0          0.000664   \n",
       "2      0.000473         0.572    198400   0.918         0          0.000431   \n",
       "3      0.000970         0.596    231453   0.661         0          0.000033   \n",
       "4      0.000036         0.520    222520   0.808         0          0.000010   \n",
       "\n",
       "   Liveness  Loudness  Mode  Popularity  Speechiness    Tempo  TimeSignature  \\\n",
       "0    0.0634    -5.030     1          35       0.0309  106.022              4   \n",
       "1    0.1740    -4.909     1          31       0.0282  120.027              4   \n",
       "2    0.0977    -3.324     0          30       0.0559  144.061              4   \n",
       "3    0.1130    -5.051     1          35       0.0254  111.975              4   \n",
       "4    0.0800    -4.553     0          21       0.0318   92.721              4   \n",
       "\n",
       "   Valence  \n",
       "0    0.365  \n",
       "1    0.408  \n",
       "2    0.370  \n",
       "3    0.183  \n",
       "4    0.666  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the wildfire data into a dataframe\n",
    "df_attributes = pd.read_csv(attribute_data)\n",
    "# Drop the columns with string values\n",
    "df_attributes.drop(columns=['Unnamed: 0','Album','Artist','Name'],inplace=True)\n",
    "# Convert the boolean column to integer\n",
    "df_attributes[\"Explicit\"] = df_attributes[\"Explicit\"].astype(int)\n",
    "# Let's see the shape and the first 5 rows of the dataframe\n",
    "print('\\033[1m'+\"The shape of the {} dataframe is {}:\" .format(\"attribute\",df_attributes.shape)+'\\033[0m')\n",
    "df_attributes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Acousticness', 'Danceability', 'Duration', 'Energy', 'Explicit', 'Instrumentalness', 'Liveness', 'Loudness', 'Mode', 'Popularity', 'Speechiness', 'Tempo', 'TimeSignature', 'Valence']\n"
     ]
    }
   ],
   "source": [
    "# Let's see the column names in the dataframe\n",
    "print(df_attributes.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 154931 entries, 0 to 154930\n",
      "Data columns (total 14 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   Acousticness      154931 non-null  float64\n",
      " 1   Danceability      154931 non-null  float64\n",
      " 2   Duration          154931 non-null  int64  \n",
      " 3   Energy            154931 non-null  float64\n",
      " 4   Explicit          154931 non-null  int32  \n",
      " 5   Instrumentalness  154931 non-null  float64\n",
      " 6   Liveness          154931 non-null  float64\n",
      " 7   Loudness          154931 non-null  float64\n",
      " 8   Mode              154931 non-null  int64  \n",
      " 9   Popularity        154931 non-null  int64  \n",
      " 10  Speechiness       154931 non-null  float64\n",
      " 11  Tempo             154931 non-null  float64\n",
      " 12  TimeSignature     154931 non-null  int64  \n",
      " 13  Valence           154931 non-null  float64\n",
      "dtypes: float64(9), int32(1), int64(4)\n",
      "memory usage: 16.0 MB\n"
     ]
    }
   ],
   "source": [
    "# Basic information of the df_fire dataframe by the info() method\n",
    "df_attributes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mMaximum Popularity is : 91\u001b[0m\n",
      "\u001b[1mMinimum Popularity is : 0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Let's see the maximum and minimum popularity\n",
    "print('\\033[1m'+\"Maximum Popularity is : {}\" .format(df_attributes[\"Popularity\"].max())+'\\033[0m')\n",
    "print('\\033[1m'+\"Minimum Popularity is : {}\" .format(df_attributes[\"Popularity\"].min())+'\\033[0m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating input and output datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154931, 13)\n",
      "(154931, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Create a copy of df_attributes\n",
    "df_copy = df_attributes.copy()\n",
    "# Create X and Y numpy arrays\n",
    "y = df_copy[['Popularity']].to_numpy() # Keep only the rank column\n",
    "df_copy.drop(columns=['Popularity'],inplace=True) # Keep only the attributes\n",
    "X = df_copy.to_numpy() # Convert the dataframe to numpy array\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating train and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to create training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing StandardScaler from sklearn library\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaler = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling both test and train data for X dataset\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install tensorflow module (if not available) by uncommenting below\n",
    "#!pip install keras\n",
    "#!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "# Converting the labels (y_train and y_test) to categorical values\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "# Creating a sequential model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the input of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "number_inputs = 13\n",
    "number_hidden_nodes = 39\n",
    "model.add(Dense(units=number_hidden_nodes,\n",
    "                activation='relu', input_dim=number_inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the output of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the output layer\n",
    "number_classes = 92 # Labels we are trying to predict (100 in this case)\n",
    "model.add(Dense(units=number_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 39)                546       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 92)                3680      \n",
      "=================================================================\n",
      "Total params: 4,226\n",
      "Trainable params: 4,226\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use categorical crossentropy for categorical data and mean squared error for regression\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3632/3632 - 2s - loss: 3.9579 - accuracy: 0.0786\n",
      "Epoch 2/100\n",
      "3632/3632 - 2s - loss: 3.9159 - accuracy: 0.0807\n",
      "Epoch 3/100\n",
      "3632/3632 - 2s - loss: 3.9100 - accuracy: 0.0807\n",
      "Epoch 4/100\n",
      "3632/3632 - 2s - loss: 3.9059 - accuracy: 0.0807\n",
      "Epoch 5/100\n",
      "3632/3632 - 2s - loss: 3.9029 - accuracy: 0.0809\n",
      "Epoch 6/100\n",
      "3632/3632 - 2s - loss: 3.9006 - accuracy: 0.0808\n",
      "Epoch 7/100\n",
      "3632/3632 - 2s - loss: 3.8986 - accuracy: 0.0810\n",
      "Epoch 8/100\n",
      "3632/3632 - 2s - loss: 3.8970 - accuracy: 0.0807\n",
      "Epoch 9/100\n",
      "3632/3632 - 2s - loss: 3.8955 - accuracy: 0.0809\n",
      "Epoch 10/100\n",
      "3632/3632 - 2s - loss: 3.8946 - accuracy: 0.0806\n",
      "Epoch 11/100\n",
      "3632/3632 - 2s - loss: 3.8936 - accuracy: 0.0813\n",
      "Epoch 12/100\n",
      "3632/3632 - 2s - loss: 3.8925 - accuracy: 0.0812\n",
      "Epoch 13/100\n",
      "3632/3632 - 2s - loss: 3.8916 - accuracy: 0.0811\n",
      "Epoch 14/100\n",
      "3632/3632 - 2s - loss: 3.8907 - accuracy: 0.0812\n",
      "Epoch 15/100\n",
      "3632/3632 - 2s - loss: 3.8899 - accuracy: 0.0812\n",
      "Epoch 16/100\n",
      "3632/3632 - 2s - loss: 3.8891 - accuracy: 0.0811\n",
      "Epoch 17/100\n",
      "3632/3632 - 2s - loss: 3.8883 - accuracy: 0.0812\n",
      "Epoch 18/100\n",
      "3632/3632 - 2s - loss: 3.8878 - accuracy: 0.0812\n",
      "Epoch 19/100\n",
      "3632/3632 - 2s - loss: 3.8870 - accuracy: 0.0812\n",
      "Epoch 20/100\n",
      "3632/3632 - 2s - loss: 3.8865 - accuracy: 0.0816\n",
      "Epoch 21/100\n",
      "3632/3632 - 2s - loss: 3.8859 - accuracy: 0.0813\n",
      "Epoch 22/100\n",
      "3632/3632 - 2s - loss: 3.8853 - accuracy: 0.0811\n",
      "Epoch 23/100\n",
      "3632/3632 - 2s - loss: 3.8846 - accuracy: 0.0816\n",
      "Epoch 24/100\n",
      "3632/3632 - 2s - loss: 3.8842 - accuracy: 0.0813\n",
      "Epoch 25/100\n",
      "3632/3632 - 2s - loss: 3.8837 - accuracy: 0.0812\n",
      "Epoch 26/100\n",
      "3632/3632 - 2s - loss: 3.8830 - accuracy: 0.0814\n",
      "Epoch 27/100\n",
      "3632/3632 - 2s - loss: 3.8826 - accuracy: 0.0816\n",
      "Epoch 28/100\n",
      "3632/3632 - 2s - loss: 3.8822 - accuracy: 0.0815\n",
      "Epoch 29/100\n",
      "3632/3632 - 2s - loss: 3.8816 - accuracy: 0.0812\n",
      "Epoch 30/100\n",
      "3632/3632 - 2s - loss: 3.8813 - accuracy: 0.0811\n",
      "Epoch 31/100\n",
      "3632/3632 - 2s - loss: 3.8808 - accuracy: 0.0817\n",
      "Epoch 32/100\n",
      "3632/3632 - 2s - loss: 3.8804 - accuracy: 0.0817\n",
      "Epoch 33/100\n",
      "3632/3632 - 2s - loss: 3.8801 - accuracy: 0.0814\n",
      "Epoch 34/100\n",
      "3632/3632 - 2s - loss: 3.8799 - accuracy: 0.0814\n",
      "Epoch 35/100\n",
      "3632/3632 - 2s - loss: 3.8797 - accuracy: 0.0810\n",
      "Epoch 36/100\n",
      "3632/3632 - 2s - loss: 3.8796 - accuracy: 0.0813\n",
      "Epoch 37/100\n",
      "3632/3632 - 2s - loss: 3.8788 - accuracy: 0.0815\n",
      "Epoch 38/100\n",
      "3632/3632 - 2s - loss: 3.8789 - accuracy: 0.0814\n",
      "Epoch 39/100\n",
      "3632/3632 - 2s - loss: 3.8783 - accuracy: 0.0816\n",
      "Epoch 40/100\n",
      "3632/3632 - 2s - loss: 3.8782 - accuracy: 0.0813\n",
      "Epoch 41/100\n",
      "3632/3632 - 2s - loss: 3.8780 - accuracy: 0.0814\n",
      "Epoch 42/100\n",
      "3632/3632 - 2s - loss: 3.8779 - accuracy: 0.0813\n",
      "Epoch 43/100\n",
      "3632/3632 - 2s - loss: 3.8771 - accuracy: 0.0816\n",
      "Epoch 44/100\n",
      "3632/3632 - 2s - loss: 3.8773 - accuracy: 0.0815\n",
      "Epoch 45/100\n",
      "3632/3632 - 2s - loss: 3.8769 - accuracy: 0.0815\n",
      "Epoch 46/100\n",
      "3632/3632 - 2s - loss: 3.8767 - accuracy: 0.0813\n",
      "Epoch 47/100\n",
      "3632/3632 - 2s - loss: 3.8766 - accuracy: 0.0815\n",
      "Epoch 48/100\n",
      "3632/3632 - 2s - loss: 3.8766 - accuracy: 0.0814\n",
      "Epoch 49/100\n",
      "3632/3632 - 2s - loss: 3.8764 - accuracy: 0.0816\n",
      "Epoch 50/100\n",
      "3632/3632 - 2s - loss: 3.8762 - accuracy: 0.0818\n",
      "Epoch 51/100\n",
      "3632/3632 - 2s - loss: 3.8761 - accuracy: 0.0813\n",
      "Epoch 52/100\n",
      "3632/3632 - 2s - loss: 3.8759 - accuracy: 0.0812\n",
      "Epoch 53/100\n",
      "3632/3632 - 2s - loss: 3.8755 - accuracy: 0.0813\n",
      "Epoch 54/100\n",
      "3632/3632 - 2s - loss: 3.8756 - accuracy: 0.0817\n",
      "Epoch 55/100\n",
      "3632/3632 - 2s - loss: 3.8755 - accuracy: 0.0815\n",
      "Epoch 56/100\n",
      "3632/3632 - 2s - loss: 3.8753 - accuracy: 0.0818\n",
      "Epoch 57/100\n",
      "3632/3632 - 2s - loss: 3.8753 - accuracy: 0.0814\n",
      "Epoch 58/100\n",
      "3632/3632 - 2s - loss: 3.8750 - accuracy: 0.0814\n",
      "Epoch 59/100\n",
      "3632/3632 - 2s - loss: 3.8750 - accuracy: 0.0812\n",
      "Epoch 60/100\n",
      "3632/3632 - 2s - loss: 3.8748 - accuracy: 0.0813\n",
      "Epoch 61/100\n",
      "3632/3632 - 2s - loss: 3.8750 - accuracy: 0.0815\n",
      "Epoch 62/100\n",
      "3632/3632 - 2s - loss: 3.8746 - accuracy: 0.0816\n",
      "Epoch 63/100\n",
      "3632/3632 - 2s - loss: 3.8747 - accuracy: 0.0814\n",
      "Epoch 64/100\n",
      "3632/3632 - 2s - loss: 3.8746 - accuracy: 0.0815\n",
      "Epoch 65/100\n",
      "3632/3632 - 2s - loss: 3.8743 - accuracy: 0.0814\n",
      "Epoch 66/100\n",
      "3632/3632 - 2s - loss: 3.8744 - accuracy: 0.0817\n",
      "Epoch 67/100\n",
      "3632/3632 - 2s - loss: 3.8743 - accuracy: 0.0815\n",
      "Epoch 68/100\n",
      "3632/3632 - 2s - loss: 3.8742 - accuracy: 0.0812\n",
      "Epoch 69/100\n",
      "3632/3632 - 2s - loss: 3.8741 - accuracy: 0.0815\n",
      "Epoch 70/100\n",
      "3632/3632 - 2s - loss: 3.8737 - accuracy: 0.0814\n",
      "Epoch 71/100\n",
      "3632/3632 - 2s - loss: 3.8739 - accuracy: 0.0814\n",
      "Epoch 72/100\n",
      "3632/3632 - 2s - loss: 3.8739 - accuracy: 0.0813\n",
      "Epoch 73/100\n",
      "3632/3632 - 2s - loss: 3.8738 - accuracy: 0.0818\n",
      "Epoch 74/100\n",
      "3632/3632 - 2s - loss: 3.8740 - accuracy: 0.0815\n",
      "Epoch 75/100\n",
      "3632/3632 - 2s - loss: 3.8735 - accuracy: 0.0812\n",
      "Epoch 76/100\n",
      "3632/3632 - 2s - loss: 3.8736 - accuracy: 0.0818\n",
      "Epoch 77/100\n",
      "3632/3632 - 2s - loss: 3.8733 - accuracy: 0.0814\n",
      "Epoch 78/100\n",
      "3632/3632 - 2s - loss: 3.8736 - accuracy: 0.0817\n",
      "Epoch 79/100\n",
      "3632/3632 - 2s - loss: 3.8735 - accuracy: 0.0814\n",
      "Epoch 80/100\n",
      "3632/3632 - 2s - loss: 3.8734 - accuracy: 0.0813\n",
      "Epoch 81/100\n",
      "3632/3632 - 2s - loss: 3.8732 - accuracy: 0.0817\n",
      "Epoch 82/100\n",
      "3632/3632 - 2s - loss: 3.8735 - accuracy: 0.0813\n",
      "Epoch 83/100\n",
      "3632/3632 - 2s - loss: 3.8734 - accuracy: 0.0814\n",
      "Epoch 84/100\n",
      "3632/3632 - 2s - loss: 3.8733 - accuracy: 0.0816\n",
      "Epoch 85/100\n",
      "3632/3632 - 2s - loss: 3.8731 - accuracy: 0.0816\n",
      "Epoch 86/100\n",
      "3632/3632 - 2s - loss: 3.8729 - accuracy: 0.0814\n",
      "Epoch 87/100\n",
      "3632/3632 - 2s - loss: 3.8730 - accuracy: 0.0816\n",
      "Epoch 88/100\n",
      "3632/3632 - 2s - loss: 3.8730 - accuracy: 0.0814\n",
      "Epoch 89/100\n",
      "3632/3632 - 2s - loss: 3.8729 - accuracy: 0.0814\n",
      "Epoch 90/100\n",
      "3632/3632 - 2s - loss: 3.8728 - accuracy: 0.0816\n",
      "Epoch 91/100\n",
      "3632/3632 - 2s - loss: 3.8729 - accuracy: 0.0812\n",
      "Epoch 92/100\n",
      "3632/3632 - 2s - loss: 3.8727 - accuracy: 0.0820\n",
      "Epoch 93/100\n",
      "3632/3632 - 2s - loss: 3.8729 - accuracy: 0.0815\n",
      "Epoch 94/100\n",
      "3632/3632 - 2s - loss: 3.8726 - accuracy: 0.0814\n",
      "Epoch 95/100\n",
      "3632/3632 - 2s - loss: 3.8728 - accuracy: 0.0813\n",
      "Epoch 96/100\n",
      "3632/3632 - 2s - loss: 3.8729 - accuracy: 0.0815\n",
      "Epoch 97/100\n",
      "3632/3632 - 2s - loss: 3.8726 - accuracy: 0.0814\n",
      "Epoch 98/100\n",
      "3632/3632 - 2s - loss: 3.8728 - accuracy: 0.0816\n",
      "Epoch 99/100\n",
      "3632/3632 - 2s - loss: 3.8726 - accuracy: 0.0813\n",
      "Epoch 100/100\n",
      "3632/3632 - 2s - loss: 3.8727 - accuracy: 0.0814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1658dcbd0c8>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit (train) the model\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100, # Thousand iterations or loops\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model using the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1211/1211 - 0s - loss: 3.9102 - accuracy: 0.0837\n",
      "Loss: 3.91015887260437, Accuracy: 0.0837012380361557\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the testing data\n",
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this model we use an additional hidden layer of 39 nodes\n",
    "deep_model = Sequential()\n",
    "deep_model.add(Dense(units=39, activation='relu', input_dim=13))\n",
    "deep_model.add(Dense(units=39, activation='relu'))\n",
    "deep_model.add(Dense(units=92, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Deep model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 39)                546       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 39)                1560      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 92)                3680      \n",
      "=================================================================\n",
      "Total params: 5,786\n",
      "Trainable params: 5,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "deep_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the deep model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the deep model\n",
    "deep_model.compile(optimizer='adam',\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the deep model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3632/3632 - 2s - loss: 3.9461 - accuracy: 0.0795\n",
      "Epoch 2/100\n",
      "3632/3632 - 2s - loss: 3.9122 - accuracy: 0.0803\n",
      "Epoch 3/100\n",
      "3632/3632 - 2s - loss: 3.9042 - accuracy: 0.0807\n",
      "Epoch 4/100\n",
      "3632/3632 - 2s - loss: 3.8987 - accuracy: 0.0807\n",
      "Epoch 5/100\n",
      "3632/3632 - 2s - loss: 3.8945 - accuracy: 0.0809\n",
      "Epoch 6/100\n",
      "3632/3632 - 2s - loss: 3.8904 - accuracy: 0.0810\n",
      "Epoch 7/100\n",
      "3632/3632 - 2s - loss: 3.8873 - accuracy: 0.0814\n",
      "Epoch 8/100\n",
      "3632/3632 - 2s - loss: 3.8853 - accuracy: 0.0812\n",
      "Epoch 9/100\n",
      "3632/3632 - 2s - loss: 3.8831 - accuracy: 0.0815\n",
      "Epoch 10/100\n",
      "3632/3632 - 2s - loss: 3.8812 - accuracy: 0.0816\n",
      "Epoch 11/100\n",
      "3632/3632 - 2s - loss: 3.8796 - accuracy: 0.0816\n",
      "Epoch 12/100\n",
      "3632/3632 - 2s - loss: 3.8775 - accuracy: 0.0819\n",
      "Epoch 13/100\n",
      "3632/3632 - 2s - loss: 3.8765 - accuracy: 0.0817\n",
      "Epoch 14/100\n",
      "3632/3632 - 2s - loss: 3.8750 - accuracy: 0.0818\n",
      "Epoch 15/100\n",
      "3632/3632 - 2s - loss: 3.8738 - accuracy: 0.0816\n",
      "Epoch 16/100\n",
      "3632/3632 - 2s - loss: 3.8722 - accuracy: 0.0817\n",
      "Epoch 17/100\n",
      "3632/3632 - 2s - loss: 3.8718 - accuracy: 0.0819\n",
      "Epoch 18/100\n",
      "3632/3632 - 2s - loss: 3.8705 - accuracy: 0.0821\n",
      "Epoch 19/100\n",
      "3632/3632 - 2s - loss: 3.8700 - accuracy: 0.0820\n",
      "Epoch 20/100\n",
      "3632/3632 - 2s - loss: 3.8689 - accuracy: 0.0820\n",
      "Epoch 21/100\n",
      "3632/3632 - 2s - loss: 3.8683 - accuracy: 0.0820\n",
      "Epoch 22/100\n",
      "3632/3632 - 2s - loss: 3.8673 - accuracy: 0.0821\n",
      "Epoch 23/100\n",
      "3632/3632 - 2s - loss: 3.8667 - accuracy: 0.0824\n",
      "Epoch 24/100\n",
      "3632/3632 - 2s - loss: 3.8658 - accuracy: 0.0818\n",
      "Epoch 25/100\n",
      "3632/3632 - 2s - loss: 3.8655 - accuracy: 0.0824\n",
      "Epoch 26/100\n",
      "3632/3632 - 2s - loss: 3.8649 - accuracy: 0.0821\n",
      "Epoch 27/100\n",
      "3632/3632 - 2s - loss: 3.8642 - accuracy: 0.0824\n",
      "Epoch 28/100\n",
      "3632/3632 - 2s - loss: 3.8638 - accuracy: 0.0822\n",
      "Epoch 29/100\n",
      "3632/3632 - 2s - loss: 3.8633 - accuracy: 0.0824\n",
      "Epoch 30/100\n",
      "3632/3632 - 2s - loss: 3.8629 - accuracy: 0.0824\n",
      "Epoch 31/100\n",
      "3632/3632 - 2s - loss: 3.8624 - accuracy: 0.0822\n",
      "Epoch 32/100\n",
      "3632/3632 - 2s - loss: 3.8617 - accuracy: 0.0823\n",
      "Epoch 33/100\n",
      "3632/3632 - 2s - loss: 3.8612 - accuracy: 0.0824\n",
      "Epoch 34/100\n",
      "3632/3632 - 2s - loss: 3.8613 - accuracy: 0.0823\n",
      "Epoch 35/100\n",
      "3632/3632 - 2s - loss: 3.8605 - accuracy: 0.0824\n",
      "Epoch 36/100\n",
      "3632/3632 - 2s - loss: 3.8604 - accuracy: 0.0822\n",
      "Epoch 37/100\n",
      "3632/3632 - 2s - loss: 3.8600 - accuracy: 0.0823\n",
      "Epoch 38/100\n",
      "3632/3632 - 2s - loss: 3.8597 - accuracy: 0.0825\n",
      "Epoch 39/100\n",
      "3632/3632 - 2s - loss: 3.8595 - accuracy: 0.0823\n",
      "Epoch 40/100\n",
      "3632/3632 - 2s - loss: 3.8590 - accuracy: 0.0824\n",
      "Epoch 41/100\n",
      "3632/3632 - 2s - loss: 3.8592 - accuracy: 0.0824\n",
      "Epoch 42/100\n",
      "3632/3632 - 2s - loss: 3.8590 - accuracy: 0.0825\n",
      "Epoch 43/100\n",
      "3632/3632 - 2s - loss: 3.8581 - accuracy: 0.0825\n",
      "Epoch 44/100\n",
      "3632/3632 - 2s - loss: 3.8578 - accuracy: 0.0824\n",
      "Epoch 45/100\n",
      "3632/3632 - 2s - loss: 3.8577 - accuracy: 0.0822\n",
      "Epoch 46/100\n",
      "3632/3632 - 2s - loss: 3.8578 - accuracy: 0.0826\n",
      "Epoch 47/100\n",
      "3632/3632 - 2s - loss: 3.8571 - accuracy: 0.0824\n",
      "Epoch 48/100\n",
      "3632/3632 - 2s - loss: 3.8576 - accuracy: 0.0831\n",
      "Epoch 49/100\n",
      "3632/3632 - 2s - loss: 3.8572 - accuracy: 0.0828\n",
      "Epoch 50/100\n",
      "3632/3632 - 2s - loss: 3.8570 - accuracy: 0.0825\n",
      "Epoch 51/100\n",
      "3632/3632 - 2s - loss: 3.8558 - accuracy: 0.0828\n",
      "Epoch 52/100\n",
      "3632/3632 - 2s - loss: 3.8566 - accuracy: 0.0827\n",
      "Epoch 53/100\n",
      "3632/3632 - 2s - loss: 3.8564 - accuracy: 0.0827\n",
      "Epoch 54/100\n",
      "3632/3632 - 2s - loss: 3.8558 - accuracy: 0.0829\n",
      "Epoch 55/100\n",
      "3632/3632 - 2s - loss: 3.8559 - accuracy: 0.0825\n",
      "Epoch 56/100\n",
      "3632/3632 - 2s - loss: 3.8562 - accuracy: 0.0829\n",
      "Epoch 57/100\n",
      "3632/3632 - 2s - loss: 3.8552 - accuracy: 0.0822\n",
      "Epoch 58/100\n",
      "3632/3632 - 2s - loss: 3.8552 - accuracy: 0.0824\n",
      "Epoch 59/100\n",
      "3632/3632 - 2s - loss: 3.8550 - accuracy: 0.0826\n",
      "Epoch 60/100\n",
      "3632/3632 - 2s - loss: 3.8553 - accuracy: 0.0829\n",
      "Epoch 61/100\n",
      "3632/3632 - 2s - loss: 3.8551 - accuracy: 0.0826\n",
      "Epoch 62/100\n",
      "3632/3632 - 2s - loss: 3.8546 - accuracy: 0.0832\n",
      "Epoch 63/100\n",
      "3632/3632 - 2s - loss: 3.8549 - accuracy: 0.0824\n",
      "Epoch 64/100\n",
      "3632/3632 - 2s - loss: 3.8543 - accuracy: 0.0826\n",
      "Epoch 65/100\n",
      "3632/3632 - 2s - loss: 3.8540 - accuracy: 0.0827\n",
      "Epoch 66/100\n",
      "3632/3632 - 2s - loss: 3.8542 - accuracy: 0.0828\n",
      "Epoch 67/100\n",
      "3632/3632 - 2s - loss: 3.8537 - accuracy: 0.0828\n",
      "Epoch 68/100\n",
      "3632/3632 - 2s - loss: 3.8539 - accuracy: 0.0828\n",
      "Epoch 69/100\n",
      "3632/3632 - 2s - loss: 3.8534 - accuracy: 0.0829\n",
      "Epoch 70/100\n",
      "3632/3632 - 2s - loss: 3.8534 - accuracy: 0.0825\n",
      "Epoch 71/100\n",
      "3632/3632 - 2s - loss: 3.8533 - accuracy: 0.0825\n",
      "Epoch 72/100\n",
      "3632/3632 - 2s - loss: 3.8534 - accuracy: 0.0824\n",
      "Epoch 73/100\n",
      "3632/3632 - 2s - loss: 3.8529 - accuracy: 0.0827\n",
      "Epoch 74/100\n",
      "3632/3632 - 2s - loss: 3.8532 - accuracy: 0.0824\n",
      "Epoch 75/100\n",
      "3632/3632 - 2s - loss: 3.8527 - accuracy: 0.0829\n",
      "Epoch 76/100\n",
      "3632/3632 - 2s - loss: 3.8526 - accuracy: 0.0828\n",
      "Epoch 77/100\n",
      "3632/3632 - 2s - loss: 3.8529 - accuracy: 0.0823\n",
      "Epoch 78/100\n",
      "3632/3632 - 2s - loss: 3.8524 - accuracy: 0.0829\n",
      "Epoch 79/100\n",
      "3632/3632 - 2s - loss: 3.8523 - accuracy: 0.0827\n",
      "Epoch 80/100\n",
      "3632/3632 - 2s - loss: 3.8525 - accuracy: 0.0828\n",
      "Epoch 81/100\n",
      "3632/3632 - 2s - loss: 3.8522 - accuracy: 0.0825\n",
      "Epoch 82/100\n",
      "3632/3632 - 2s - loss: 3.8524 - accuracy: 0.0828\n",
      "Epoch 83/100\n",
      "3632/3632 - 2s - loss: 3.8518 - accuracy: 0.0827\n",
      "Epoch 84/100\n",
      "3632/3632 - 2s - loss: 3.8520 - accuracy: 0.0824\n",
      "Epoch 85/100\n",
      "3632/3632 - 2s - loss: 3.8515 - accuracy: 0.0827\n",
      "Epoch 86/100\n",
      "3632/3632 - 2s - loss: 3.8513 - accuracy: 0.0829\n",
      "Epoch 87/100\n",
      "3632/3632 - 2s - loss: 3.8519 - accuracy: 0.0828\n",
      "Epoch 88/100\n",
      "3632/3632 - 2s - loss: 3.8514 - accuracy: 0.0824\n",
      "Epoch 89/100\n",
      "3632/3632 - 2s - loss: 3.8511 - accuracy: 0.0830\n",
      "Epoch 90/100\n",
      "3632/3632 - 2s - loss: 3.8509 - accuracy: 0.0831\n",
      "Epoch 91/100\n",
      "3632/3632 - 2s - loss: 3.8510 - accuracy: 0.0831\n",
      "Epoch 92/100\n",
      "3632/3632 - 2s - loss: 3.8507 - accuracy: 0.0830\n",
      "Epoch 93/100\n",
      "3632/3632 - 2s - loss: 3.8510 - accuracy: 0.0830\n",
      "Epoch 94/100\n",
      "3632/3632 - 2s - loss: 3.8509 - accuracy: 0.0829\n",
      "Epoch 95/100\n",
      "3632/3632 - 2s - loss: 3.8505 - accuracy: 0.0831\n",
      "Epoch 96/100\n",
      "3632/3632 - 2s - loss: 3.8506 - accuracy: 0.0828\n",
      "Epoch 97/100\n",
      "3632/3632 - 2s - loss: 3.8506 - accuracy: 0.0829\n",
      "Epoch 98/100\n",
      "3632/3632 - 2s - loss: 3.8509 - accuracy: 0.0824\n",
      "Epoch 99/100\n",
      "3632/3632 - 2s - loss: 3.8500 - accuracy: 0.0829\n",
      "Epoch 100/100\n",
      "3632/3632 - 2s - loss: 3.8506 - accuracy: 0.0829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1658dbc88c8>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit (train) the deep model\n",
    "deep_model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1211/1211 - 0s - loss: 3.9211 - accuracy: 0.0827\n",
      "Deep Neural Network - Loss: 3.921096086502075, Accuracy: 0.08269434422254562\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the deep model using the testing data\n",
    "model_loss, model_accuracy = deep_model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Deep Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
